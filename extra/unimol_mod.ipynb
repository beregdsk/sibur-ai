{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8673972",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from unimol_tools.models.unimolv2 import UniMolV2Model, LinearHead\n",
    "from unimol_tools.data.conformer import UniMolV2Feature, ConformerGen, mol2unimolv2, inner_smi2coords, create_mol_from_atoms_and_coords\n",
    "from unimol_tools.data.datahub import DataHub, MolDataReader, TargetScaler\n",
    "from unimol_tools.tasks.trainer import Trainer\n",
    "from unimol_tools.train import MolTrain\n",
    "from unimol_tools.predict import MolPredict\n",
    "from unimol_tools.models.nnmodel import NNModel, NNMODEL_REGISTER\n",
    "from unimol_tools.utils import logger\n",
    "import os\n",
    "import math\n",
    "import joblib\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from rdkit.Chem import Descriptors, rdEHTTools\n",
    "\n",
    "class UniMolFusion(UniMolV2Model):\n",
    "    def __init__(self, output_dim=2, model_size='84m', **params):\n",
    "        super().__init__(output_dim, model_size, **params)\n",
    "\n",
    "        self.graph_feature_dim = params.get('graph_feature_dim', None)\n",
    "        proj_dim = self.args.encoder_embed_dim\n",
    "        if self.graph_feature_dim is not None:\n",
    "            self.graph_proj = nn.Sequential(\n",
    "                nn.Linear(self.graph_feature_dim, proj_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(self.args.pooler_dropout),\n",
    "            )\n",
    "\n",
    "        final_input_dim = self.args.encoder_embed_dim + (proj_dim if self.graph_feature_dim else 0)\n",
    "        self.classification_head = LinearHead(\n",
    "            input_dim=final_input_dim,\n",
    "            num_classes=self.output_dim,\n",
    "            pooler_dropout=self.args.pooler_dropout,\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        atom_feat,\n",
    "        atom_mask,\n",
    "        edge_feat,\n",
    "        shortest_path,\n",
    "        degree,\n",
    "        pair_type,\n",
    "        attn_bias,\n",
    "        src_tokens,\n",
    "        src_coord,\n",
    "        return_repr=False,\n",
    "        return_atomic_reprs=False,\n",
    "        graph_feat=None,\n",
    "        **kwargs\n",
    "    ):\n",
    "        pos = src_coord\n",
    "\n",
    "        n_mol, n_atom = atom_feat.shape[:2]\n",
    "        token_feat = self.embed_tokens(src_tokens)\n",
    "        x = self.atom_feature({'atom_feat': atom_feat, 'degree': degree}, token_feat)\n",
    "\n",
    "        dtype = self.dtype\n",
    "\n",
    "        x = x.type(dtype)\n",
    "\n",
    "        attn_mask = attn_bias.clone()\n",
    "        attn_bias = torch.zeros_like(attn_mask)\n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(\n",
    "            1, self.args.encoder_attention_heads, 1, 1\n",
    "        )\n",
    "        attn_bias = attn_bias.unsqueeze(-1).repeat(1, 1, 1, self.args.pair_embed_dim)\n",
    "        attn_bias = self.edge_feature(\n",
    "            {'shortest_path': shortest_path, 'edge_feat': edge_feat}, attn_bias\n",
    "        )\n",
    "        attn_mask = attn_mask.type(self.dtype)\n",
    "\n",
    "        atom_mask_cls = torch.cat(\n",
    "            [\n",
    "                torch.ones(n_mol, 1, device=atom_mask.device, dtype=atom_mask.dtype),\n",
    "                atom_mask,\n",
    "            ],\n",
    "            dim=1,\n",
    "        ).type(self.dtype)\n",
    "\n",
    "        pair_mask = atom_mask_cls.unsqueeze(-1) * atom_mask_cls.unsqueeze(-2)\n",
    "\n",
    "        def one_block(x, pos, return_x=False):\n",
    "            delta_pos = pos.unsqueeze(1) - pos.unsqueeze(2)\n",
    "            dist = delta_pos.norm(dim=-1)\n",
    "            attn_bias_3d = self.se3_invariant_kernel(dist.detach(), pair_type)\n",
    "            new_attn_bias = attn_bias.clone()\n",
    "            new_attn_bias[:, 1:, 1:, :] = new_attn_bias[:, 1:, 1:, :] + attn_bias_3d\n",
    "            new_attn_bias = new_attn_bias.type(dtype)\n",
    "            x, pair = self.encoder(\n",
    "                x,\n",
    "                new_attn_bias,\n",
    "                atom_mask=atom_mask_cls,\n",
    "                pair_mask=pair_mask,\n",
    "                attn_mask=attn_mask,\n",
    "            )\n",
    "            node_output = self.movement_pred_head(\n",
    "                x[:, 1:, :],\n",
    "                pair[:, 1:, 1:, :],\n",
    "                attn_mask[:, :, 1:, 1:],\n",
    "                delta_pos.detach(),\n",
    "            )\n",
    "            if return_x:\n",
    "                return x, pair, pos + node_output\n",
    "            else:\n",
    "                return pos + node_output\n",
    "\n",
    "        x, pair, pos = one_block(x, pos, return_x=True)\n",
    "        cls_repr = x[:, 0, :]  # CLS token repr\n",
    "        all_repr = x[:, :, :]  # all token repr\n",
    "\n",
    "        if graph_feat is not None:\n",
    "            graph_repr = self.graph_proj(graph_feat)\n",
    "            cls_repr = torch.concat([cls_repr, graph_repr], dim=-1)\n",
    "\n",
    "        if return_repr:\n",
    "            filtered_tensors = []\n",
    "            filtered_coords = []\n",
    "\n",
    "            for tokens, coord in zip(src_tokens, src_coord):\n",
    "                filtered_tensor = tokens[\n",
    "                    (tokens != 0) & (tokens != 1) & (tokens != 2)\n",
    "                ]  # filter out BOS(0), EOS(1), PAD(2)\n",
    "                filtered_coord = coord[(tokens != 0) & (tokens != 1) & (tokens != 2)]\n",
    "                filtered_tensors.append(filtered_tensor)\n",
    "                filtered_coords.append(filtered_coord)\n",
    "\n",
    "            lengths = [\n",
    "                len(filtered_tensor) for filtered_tensor in filtered_tensors\n",
    "            ]  # Compute the lengths of the filtered tensors\n",
    "            if return_atomic_reprs:\n",
    "                cls_atomic_reprs = []\n",
    "                atomic_symbols = []\n",
    "                for i in range(len(all_repr)):\n",
    "                    atomic_reprs = x[i, 1 : lengths[i] + 1, :]\n",
    "                    atomic_symbol = filtered_tensors[i]\n",
    "                    atomic_symbols.append(atomic_symbol)\n",
    "                    cls_atomic_reprs.append(atomic_reprs)\n",
    "                return {\n",
    "                    'cls_repr': cls_repr,\n",
    "                    'atomic_symbol': atomic_symbols,\n",
    "                    'atomic_coords': filtered_coords,\n",
    "                    'atomic_reprs': cls_atomic_reprs,\n",
    "                }\n",
    "            else:\n",
    "                return {'cls_repr': cls_repr}\n",
    "\n",
    "        logits = self.classification_head(cls_repr)\n",
    "        return logits\n",
    "    \n",
    "    def batch_collate_fn(self, samples):\n",
    "        batch, label = super().batch_collate_fn(samples)\n",
    "\n",
    "        if 'graph_feat' in samples[0][0]:\n",
    "            batch['graph_feat'] = torch.stack([torch.tensor(s[0]['graph_feat']) for s in samples])\n",
    "                                              \n",
    "        return batch, label\n",
    "\n",
    "def calc_qc_properties(mol):\n",
    "    if mol and mol.GetNumConformers() > 0:\n",
    "        _, result = rdEHTTools.RunMol(mol)\n",
    "\n",
    "        orbitals = result.GetOrbitalEnergies()\n",
    "\n",
    "        HOMO = orbitals[math.ceil(result.numElectrons / 2)]\n",
    "        LUMO = orbitals[math.ceil(result.numElectrons / 2) + 1]\n",
    "        energy = result.totalEnergy\n",
    "        charges = result.GetAtomicCharges()\n",
    "        dipole = 0\n",
    "        for pos, charge in zip(mol.GetConformer(0).GetPositions(), charges):\n",
    "            dipole += pos * charge\n",
    "\n",
    "        return [HOMO, LUMO, energy, np.linalg.norm(dipole)]\n",
    "\n",
    "    return [None] * 4\n",
    "\n",
    "def mol2unimolfusion(mol, max_atoms=128, remove_hs=True, gen_graph_features=True, **params):\n",
    "    feat = mol2unimolv2(mol, max_atoms, remove_hs, **params)\n",
    "\n",
    "    if gen_graph_features:\n",
    "        graph_feat = calc_qc_properties(mol)\n",
    "        graph_feat += list(Descriptors.rdMolDescriptors.CalcCrippenDescriptors(mol))\n",
    "        graph_feat += [Descriptors.rdMolDescriptors.CalcTPSA(mol)]\n",
    "        graph_feat += [Descriptors.BalabanJ(mol)]\n",
    "        graph_feat += [Descriptors.BertzCT(mol)]\n",
    "        feat['graph_feat'] = graph_feat\n",
    "\n",
    "    return feat\n",
    "\n",
    "class UniMolFusionFeature(UniMolV2Feature):\n",
    "    def single_process(self, smiles):\n",
    "        \"\"\"\n",
    "        Processes a single SMILES string to generate conformers using the specified method.\n",
    "\n",
    "        :param smiles: (str) The SMILES string representing the molecule.\n",
    "        :return: A unimolecular data representation (dictionary) of the molecule.\n",
    "        :raises ValueError: If the conformer generation method is unrecognized.\n",
    "        \"\"\"\n",
    "        if self.method == 'rdkit_random':\n",
    "            mol = inner_smi2coords(\n",
    "                smiles,\n",
    "                seed=self.seed,\n",
    "                mode=self.mode,\n",
    "                remove_hs=self.remove_hs,\n",
    "                return_mol=True,\n",
    "            )\n",
    "            return mol2unimolfusion(mol, self.max_atoms, remove_hs=self.remove_hs)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Unknown conformer generation method: {}'.format(self.method)\n",
    "            )\n",
    "\n",
    "    def transform_raw(self, atoms_list, coordinates_list):\n",
    "\n",
    "        inputs = []\n",
    "        for atoms, coordinates in zip(atoms_list, coordinates_list):\n",
    "            mol = create_mol_from_atoms_and_coords(atoms, coordinates)\n",
    "            inputs.append(mol2unimolfusion(mol, self.max_atoms, remove_hs=self.remove_hs))\n",
    "        return inputs\n",
    "\n",
    "class MolTrainFusion(MolTrain):\n",
    "    def __init__(self, task='classification', data_type='molecule', epochs=10, learning_rate=0.0001, batch_size=16, early_stopping=5, metrics=\"none\", split='random', split_group_col='scaffold', kfold=5, save_path='./exp', remove_hs=False, smiles_col='SMILES', target_cols=None, target_col_prefix='TARGET', target_anomaly_check=False, smiles_check=\"filter\", target_normalize=\"auto\", max_norm=5, use_cuda=True, use_amp=True, use_ddp=False, use_gpu=\"all\", freeze_layers=None, freeze_layers_reversed=False, load_model_dir=None, model_name='unimolv1', model_size='84m', **params):\n",
    "        super().__init__(task, data_type, epochs, learning_rate, batch_size, early_stopping, metrics, split, split_group_col, kfold, save_path, remove_hs, smiles_col, target_cols, target_col_prefix, target_anomaly_check, smiles_check, target_normalize, max_norm, use_cuda, use_amp, use_ddp, use_gpu, freeze_layers, freeze_layers_reversed, load_model_dir, model_name, model_size, **params)\n",
    "        self.config['grap']\n",
    "    \n",
    "    def fit(self, data):\n",
    "        if self.config.model_name == 'unimolfusion':\n",
    "            self.datahub = DataHubFusion(\n",
    "                data=data, is_train=True, save_path=self.save_path, **self.config\n",
    "            )\n",
    "        else:\n",
    "            self.datahub = DataHub(\n",
    "                data=data, is_train=True, save_path=self.save_path, **self.config\n",
    "            )\n",
    "        self.data = self.datahub.data\n",
    "        self.update_and_save_config()\n",
    "        self.trainer = Trainer(save_path=self.save_path, **self.config)\n",
    "        self.model = NNModel(self.data, self.trainer, **self.config)\n",
    "        self.model.run()\n",
    "        scalar = self.data['target_scaler']\n",
    "        y_pred = self.model.cv['pred']\n",
    "        y_true = np.array(self.data['target'])\n",
    "        metrics = self.trainer.metrics\n",
    "        if scalar is not None:\n",
    "            y_pred = scalar.inverse_transform(y_pred)\n",
    "            y_true = scalar.inverse_transform(y_true)\n",
    "\n",
    "        if self.config[\"task\"] in ['classification', 'multilabel_classification']:\n",
    "            threshold = metrics.calculate_classification_threshold(y_true, y_pred)\n",
    "            joblib.dump(threshold, os.path.join(self.save_path, 'threshold.dat'))\n",
    "\n",
    "        self.cv_pred = y_pred\n",
    "        return\n",
    "    \n",
    "class DataHubFusion(DataHub):\n",
    "    def _init_data(self, **params):\n",
    "        self.data = MolDataReader().read_data(self.data, self.is_train, **params)\n",
    "        self.data['target_scaler'] = TargetScaler(\n",
    "            self.ss_method, self.task, self.save_path\n",
    "        )\n",
    "        if self.task == 'regression':\n",
    "            target = np.array(self.data['raw_target']).reshape(-1, 1).astype(np.float32)\n",
    "            if self.is_train:\n",
    "                self.data['target_scaler'].fit(target, self.save_path)\n",
    "                self.data['target'] = self.data['target_scaler'].transform(target)\n",
    "            else:\n",
    "                self.data['target'] = target\n",
    "        elif self.task == 'classification':\n",
    "            target = np.array(self.data['raw_target']).reshape(-1, 1).astype(np.int32)\n",
    "            self.data['target'] = target\n",
    "        elif self.task == 'multiclass':\n",
    "            target = np.array(self.data['raw_target']).reshape(-1, 1).astype(np.int32)\n",
    "            self.data['target'] = target\n",
    "            if not self.is_train:\n",
    "                self.data['multiclass_cnt'] = self.multiclass_cnt\n",
    "        elif self.task == 'multilabel_regression':\n",
    "            target = (\n",
    "                np.array(self.data['raw_target'])\n",
    "                .reshape(-1, self.data['num_classes'])\n",
    "                .astype(np.float32)\n",
    "            )\n",
    "            if self.is_train:\n",
    "                self.data['target_scaler'].fit(target, self.save_path)\n",
    "                self.data['target'] = self.data['target_scaler'].transform(target)\n",
    "            else:\n",
    "                self.data['target'] = target\n",
    "        elif self.task == 'multilabel_classification':\n",
    "            target = (\n",
    "                np.array(self.data['raw_target'])\n",
    "                .reshape(-1, self.data['num_classes'])\n",
    "                .astype(np.int32)\n",
    "            )\n",
    "            self.data['target'] = target\n",
    "        elif self.task == 'repr':\n",
    "            self.data['target'] = self.data['raw_target']\n",
    "        else:\n",
    "            raise ValueError('Unknown task: {}'.format(self.task))\n",
    "\n",
    "        if params.get('model_name', None) == 'unimolv1':\n",
    "            if 'atoms' in self.data and 'coordinates' in self.data:\n",
    "                no_h_list = ConformerGen(**params).transform_raw(\n",
    "                    self.data['atoms'], self.data['coordinates']\n",
    "                )\n",
    "            else:\n",
    "                smiles_list = self.data[\"smiles\"]\n",
    "                no_h_list = ConformerGen(**params).transform(smiles_list)\n",
    "        elif params.get('model_name', None) == 'unimolv2':\n",
    "            if 'atoms' in self.data and 'coordinates' in self.data:\n",
    "                no_h_list = UniMolV2Feature(**params).transform_raw(\n",
    "                    self.data['atoms'], self.data['coordinates']\n",
    "                )\n",
    "            else:\n",
    "                smiles_list = self.data[\"smiles\"]\n",
    "                no_h_list = UniMolV2Feature(**params).transform(smiles_list)\n",
    "        elif params.get('model_name', None) == 'unimolfusion':\n",
    "            if 'atoms' in self.data and 'coordinates' in self.data:\n",
    "                no_h_list = UniMolFusionFeature(**params).transform_raw(\n",
    "                    self.data['atoms'], self.data['coordinates']\n",
    "                )\n",
    "            else:\n",
    "                smiles_list = self.data[\"smiles\"]\n",
    "                no_h_list = UniMolFusionFeature(**params).transform(smiles_list)\n",
    "\n",
    "        self.data['unimol_input'] = no_h_list\n",
    "\n",
    "class NNModelFusion(NNModel):\n",
    "    def _init_model(self, model_name, **params):\n",
    "        if self.task in ['regression', 'multilabel_regression']:\n",
    "            params['pooler_dropout'] = 0\n",
    "            logger.debug(\"set pooler_dropout to 0 for regression task\")\n",
    "        else:\n",
    "            pass\n",
    "        freeze_layers = params.get('freeze_layers', None)\n",
    "        freeze_layers_reversed = params.get('freeze_layers_reversed', False)\n",
    "        if model_name in NNMODEL_REGISTER or model_name == 'unimolfusion':\n",
    "            model = NNMODEL_REGISTER[model_name](**params) if model_name in NNMODEL_REGISTER \\\n",
    "                    else UniMolFusion(**params)\n",
    "            if isinstance(freeze_layers, str):\n",
    "                freeze_layers = freeze_layers.replace(' ', '').split(',')\n",
    "            if isinstance(freeze_layers, list):\n",
    "                for layer_name, layer_param in model.named_parameters():\n",
    "                    should_freeze = any(\n",
    "                        layer_name.startswith(freeze_layer)\n",
    "                        for freeze_layer in freeze_layers\n",
    "                    )\n",
    "                    layer_param.requires_grad = not (\n",
    "                        freeze_layers_reversed ^ should_freeze\n",
    "                    )\n",
    "        else:\n",
    "            raise ValueError('Unknown model: {}'.format(self.model_name))\n",
    "        return model\n",
    "    \n",
    "class MolPredictFusion(MolPredict):\n",
    "    def predict(self, data, save_path=None, metrics='none'):\n",
    "        self.save_path = save_path\n",
    "        if not metrics or metrics != 'none':\n",
    "            self.config.metrics = metrics\n",
    "        ## load test data\n",
    "        if self.config.model_name == 'unimolfusion':\n",
    "            self.datahub = DataHubFusion(\n",
    "                data=data, is_train=False, save_path=self.load_model, **self.config\n",
    "            )\n",
    "            self.config.use_dpp = False\n",
    "            self.trainer = Trainer(\n",
    "                save_path=self.load_model, **self.config\n",
    "            )\n",
    "            self.model = NNModelFusion(self.datahub.data, self.trainer, **self.config)\n",
    "        else:\n",
    "            self.datahub = DataHub(\n",
    "                data=data, is_train=False, save_path=self.load_model, **self.config\n",
    "            )\n",
    "            self.config.use_ddp = False\n",
    "            self.trainer = Trainer(\n",
    "                save_path=self.load_model, **self.config\n",
    "            )\n",
    "            self.model = NNModel(self.datahub.data, self.trainer, **self.config)\n",
    "\n",
    "        self.model.evaluate(self.trainer, self.load_model)\n",
    "\n",
    "        y_pred = self.model.cv['test_pred']\n",
    "        scalar = self.datahub.data['target_scaler']\n",
    "        if scalar is not None:\n",
    "            y_pred = scalar.inverse_transform(y_pred)\n",
    "\n",
    "        df = self.datahub.data['raw_data'].copy()\n",
    "        predict_cols = ['predict_' + col for col in self.target_cols]\n",
    "        if self.task == 'multiclass' and self.config.multiclass_cnt is not None:\n",
    "            prob_cols = ['prob_' + str(i) for i in range(self.config.multiclass_cnt)]\n",
    "            df[prob_cols] = y_pred\n",
    "            df[predict_cols] = np.argmax(y_pred, axis=1).reshape(-1, 1)\n",
    "        elif self.task in ['classification', 'multilabel_classification']:\n",
    "            threshold = joblib.load(\n",
    "                open(os.path.join(self.load_model, 'threshold.dat'), \"rb\")\n",
    "            )\n",
    "            prob_cols = ['prob_' + col for col in self.target_cols]\n",
    "            df[prob_cols] = y_pred\n",
    "            df[predict_cols] = (y_pred > threshold).astype(int)\n",
    "        else:\n",
    "            prob_cols = predict_cols\n",
    "            df[predict_cols] = y_pred\n",
    "        if self.save_path:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "        if not (df[self.target_cols] == -1.0).all().all():\n",
    "            metrics = self.trainer.metrics.cal_metric(\n",
    "                df[self.target_cols].values, df[prob_cols].values\n",
    "            )\n",
    "            logger.info(\"final predict metrics score: \\n{}\".format(metrics))\n",
    "            if self.save_path:\n",
    "                joblib.dump(metrics, os.path.join(self.save_path, 'test_metric.result'))\n",
    "                with open(os.path.join(self.save_path, 'test_metric.json'), 'w') as f:\n",
    "                    json.dump(metrics, f)\n",
    "        else:\n",
    "            df.drop(self.target_cols, axis=1, inplace=True)\n",
    "        if self.save_path:\n",
    "            prefix = (\n",
    "                data.split('/')[-1].split('.')[0] if isinstance(data, str) else 'test'\n",
    "            )\n",
    "            self.save_predict(df, self.save_path, prefix)\n",
    "            logger.info(\"pipeline finish!\")\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5028756c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from rdkit import RDLogger\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "clf = MolTrainFusion(\n",
    "    task='regression', \n",
    "    data_type='molecule', \n",
    "    model_name='unimolfusion',\n",
    "    epochs=1, \n",
    "    batch_size=32, \n",
    "    metrics='mse',\n",
    "    target_cols=['LogP'],\n",
    "    use_cuda=False,\n",
    "    kfold=1,\n",
    "    remove_hs=True,\n",
    "    target_anomaly_check=True,\n",
    "    graph_feature_dim=9\n",
    ")\n",
    "pred = clf.fit(data='clean_train.csv')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
